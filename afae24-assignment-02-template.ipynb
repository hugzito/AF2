{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Fairness, Accountability, and Ethics, Spring 2024\n",
    "\n",
    "## Mandatory Assignment 2\n",
    "\n",
    "Please use the following code to prepare the dataset.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from folktables.acs import adult_filter\n",
    "from folktables import ACSDataSource, BasicProblem, generate_categories\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(0)\n",
    "from sklearn.utils.validation import check_random_state\n",
    "check_random_state(0)\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "\n",
    "\n",
    "def adult_filter(data):\n",
    "    \"\"\"Mimic the filters in place for Adult data.\n",
    "    Adult documentation notes: Extraction was done by Barry Becker from\n",
    "    the 1994 Census database. A set of reasonably clean records was extracted\n",
    "    using the following conditions:\n",
    "    ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
    "    \"\"\"\n",
    "    df = data\n",
    "    df = df[df['AGEP'] > 16]\n",
    "    df = df[df['PINCP'] > 100]\n",
    "    df = df[df['WKHP'] > 0]\n",
    "    df = df[df['PWGTP'] >= 1]\n",
    "    df = df[df[\"RAC1P\"] < 3] ## keep only Whites and African-Americans\n",
    "    return df\n",
    "\n",
    "\n",
    "ACSIncomeNew = BasicProblem(\n",
    "    features=[\n",
    "        'AGEP',\n",
    "        'COW',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'RELP',\n",
    "        'WKHP',\n",
    "        'PWGTP',\n",
    "        'SEX',\n",
    "        'RAC1P',\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > 25000,    \n",
    "    group=['SEX', 'RAC1P'],\n",
    "    preprocess=adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n",
    "\n",
    "definition_df = data_source.get_definitions(download=True)\n",
    "categories = generate_categories(features=ACSIncomeNew.features, definition_df=definition_df)\n",
    "features, labels, groups = ACSIncomeNew.df_to_pandas(acs_data, categories=categories, dummies=True)\n",
    "\n",
    "# Drop the \"redundant\" columns\n",
    "features = features.drop([\"RAC1P_White alone\", \n",
    "                          \"SEX_Male\", \n",
    "                          \"SCHL_1 or more years of college credit, no degree\",  \n",
    "                          \"MAR_Divorced\", \n",
    "                          \"RELP_Adopted son or daughter\",\n",
    "                          'COW_Working without pay in family business or farm' ], axis = 1) \n",
    "\n",
    "print(\"Columns with the protected features:\")\n",
    "for i, f in enumerate(features.columns):\n",
    "    if (\"RAC1P\" in f) or (\"SEX\" in f):\n",
    "        print(\"Column ID: %s\" %i, \"(%s)\"%f)\n",
    "        \n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "### Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sample_indices = random.sample(range(len(features)), 20000)\n",
    "features1, labels1 = features.iloc[sample_indices], labels.iloc[sample_indices]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features1, labels1, test_size=0.2, random_state=0)\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(columns= X_train.columns, data= X_train, index = X_train.index)\n",
    "X_test = pd.DataFrame(columns= X_test.columns, data = X_test, index= X_test.index)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "# shuffle the index of training data\n",
    "# X_train = X_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "### Create one classifier to predict income on RAW DATA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=3, random_state=0)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "### Report general accuracy \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, auc, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "probs = gbc.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "preds = accuracy_score(y_test, probs > 0.5)\n",
    "\n",
    "print('Scores across all groups.')\n",
    "print('AUC: ', auc(fpr, tpr))\n",
    "print('Accuracy: ', preds)\n",
    "pipe = Pipeline(steps=[('scaler', StandardScaler()), ('classifier', gbc)])\n",
    "print('Overall cross val score: ', cross_val_score(pipe , X_train, y_train).mean())\n",
    "print('---------------------------')\n",
    "\n",
    "### report accuracy for gender groups and races\n",
    "accuracies_female, accuracies_nonfemale = [], []\n",
    "accuracies_black, accuracies_nonblack = [], []\n",
    "for j in [0, 4000, 8000, 12000]:\n",
    "    test = list(range(j, j+4000))\n",
    "    X_test_temp = X_train.iloc[test]\n",
    "    y_test_temp = y_train.iloc[test]\n",
    "    X_train_temp = X_train.drop(test)\n",
    "    y_train_temp = y_train.drop(test)\n",
    "    pipe = Pipeline(steps=[('scaler', StandardScaler()), ('classifier', gbc)])\n",
    "    pipe.fit(X_train_temp, y_train_temp)\n",
    "    for i in set(X_train['RAC1P_Black or African American alone']):\n",
    "        X_test_temp_group = X_test_temp[X_test_temp['RAC1P_Black or African American alone'] == i]\n",
    "        y_test_temp_group = y_test_temp.loc[X_test_temp_group.index]\n",
    "        temp_preds = pipe.predict(X_test_temp_group)\n",
    "        accuracy = accuracy_score(y_test_temp_group, temp_preds)\n",
    "        if i > 0:\n",
    "            accuracies_black.append(accuracy)\n",
    "        else:\n",
    "            accuracies_nonblack.append(accuracy)\n",
    "    for i in set(X_train['SEX_Female']):\n",
    "        X_test_temp_group = X_test_temp[X_test_temp['SEX_Female'] == i]\n",
    "        y_test_temp_group = y_test_temp.loc[X_test_temp_group.index]\n",
    "        temp_preds = pipe.predict(X_test_temp_group)\n",
    "        accuracy = accuracy_score(y_test_temp_group, temp_preds)\n",
    "        if i > 0:\n",
    "            accuracies_female.append(accuracy)\n",
    "        else:\n",
    "            accuracies_nonfemale.append(accuracy)\n",
    "\n",
    "print(f'Accuracy for Black: {np.mean(accuracies_black)}')\n",
    "print(f'Accuracy for Non-Black: {np.mean(accuracies_nonblack)}')\n",
    "print(f'Accuracy for Female: {np.mean(accuracies_female)}')\n",
    "print(f'Accuracy for Non-Female: {np.mean(accuracies_nonfemale)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lambdas = np.linspace(0, 1, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(features['RAC1P_Black or African American alone'].value_counts()/len(features))\n",
    "print(features1['RAC1P_Black or African American alone'].value_counts()/len(features1))\n",
    "print(features['SEX_Female'].value_counts()/len(features))\n",
    "print(features1['SEX_Female'].value_counts()/len(features1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(data = scaler.fit_transform(X_train), columns = X_train.columns, index = X_train.index)\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "Xs_train_p = X_train.values[:, 54:]\n",
    "Xs_test_p = X_test.values[:, 54:]\n",
    "Xs_train_np = X_train.values[:, :54]\n",
    "Xs_test_np = X_test.values[:, :54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ### Create a fairer version of the dataset to protect select groups\n",
    "\n",
    "plots = [0.96969697, 1.97979798, 3.03030303, 0.04040404]\n",
    "def debias_features(Xs_np, Xs_p, lambda_param=0.7):\n",
    "    import scipy\n",
    "    assert Xs_np.shape[0]==Xs_p.shape[0]\n",
    "\n",
    "\n",
    "    orthbasis = scipy.linalg.orth(Xs_p)\n",
    "\n",
    "    orthbasis_projection = orthbasis @ orthbasis.T @ Xs_np\n",
    "    Xs_np_debiased = Xs_np - orthbasis_projection + lambda_param * orthbasis_projection\n",
    "\n",
    "    return Xs_np_debiased\n",
    "\n",
    "\n",
    "accuracies_all = []\n",
    "accuracies_sex_1 = []\n",
    "accuracies_sex_2 = []\n",
    "accuracies_race_1 = []\n",
    "accuracies_race_2 = []\n",
    "protected_cols = ['RAC1P_Black or African American alone', 'SEX_Female']\n",
    "\n",
    "for idx, i in enumerate([0.1, 1/3, 0.5, 2/3, 1]):\n",
    "    X_train_unprotected_debiased = debias_features(Xs_train_np, Xs_train_p, i)\n",
    "    X_train_debiased = np.concatenate([X_train_unprotected_debiased, Xs_train_p], axis=1)\n",
    "    # Train a classifier on the debiased data for each group\n",
    "    gbc.fit(X_train_debiased, y_train)\n",
    "    preds = gbc.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    accuracies_all.append(accuracy)\n",
    "    X_test_men = X_test[X_test['SEX_Female'] > 0]\n",
    "    X_test_women = X_test[X_test['SEX_Female'] < 0]\n",
    "    y_test_men = y_test.loc[X_test_men.index]\n",
    "    y_test_women = y_test.loc[X_test_women.index]\n",
    "    X_test_black = X_test[X_test['RAC1P_Black or African American alone'] > 0]\n",
    "    X_test_non_black = X_test[X_test['RAC1P_Black or African American alone'] < 0]\n",
    "    y_test_black = y_test.loc[X_test_black.index]\n",
    "    y_test_non_black = y_test.loc[X_test_non_black.index]\n",
    "    accuracies_race_1.append(accuracy_score(y_test_black, gbc.predict(X_test_black)))\n",
    "    accuracies_race_2.append(accuracy_score(y_test_non_black, gbc.predict(X_test_non_black)))\n",
    "    accuracies_sex_1.append(accuracy_score(y_test_women, gbc.predict(X_test_women)))\n",
    "    accuracies_sex_2.append(accuracy_score(y_test_men, gbc.predict(X_test_men)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "stats = pd.DataFrame()\n",
    "stats.index = [0.1, 1/3,0.5, 2/3, 1]\n",
    "stats['All'] = accuracies_all\n",
    "stats['Women'] = accuracies_sex_1\n",
    "stats['Men'] = accuracies_sex_2\n",
    "stats['Black'] = accuracies_race_1\n",
    "stats['Non-Black'] = accuracies_race_2\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(data=stats, x = stats.index, y = stats['All'], label = 'All', markers=True)\n",
    "sns.lineplot(data=stats, x = stats.index, y = 'Men', label = 'men', markers=True)\n",
    "sns.lineplot(data=stats, x = stats.index, y = 'Women', label = 'Women', markers=True)\n",
    "sns.lineplot(data=stats, x = stats.index, y = 'Black', label = 'Black', markers=True)\n",
    "sns.lineplot(data=stats, x = stats.index, y = 'Non-Black', label = 'Non-Black', markers=True)\n",
    "\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Lambda')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('Accuracy for Black', accuracies_race_1)\n",
    "print('Accuracy for Non-Black', accuracies_race_2)\n",
    "print('Accuracy for Women', accuracies_sex_1)\n",
    "print('Accuracy for Men', accuracies_sex_2)\n",
    "print('Accuracy for all', accuracies_all)\n",
    "\n",
    "diff_sex = []\n",
    "diff_race = []\n",
    "for i in zip(accuracies_race_1, accuracies_race_2, accuracies_sex_1, accuracies_sex_2):\n",
    "    diff_race.append(abs( i[0] - i[1]))\n",
    "    diff_sex.append(abs(i[2] - i[3]))\n",
    "overall_diff = []\n",
    "for i in zip(diff_race, diff_sex):\n",
    "    overall_diff.append(i[0] + i[1])\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.lineplot(x=stats.index, y = diff_race, label = 'Race')\n",
    "sns.lineplot(x = stats.index, y = diff_sex, label = 'Sex')\n",
    "sns.lineplot(x = stats.index, y = overall_diff, label = 'Overall')\n",
    "plt.ylabel('% Difference')\n",
    "plt.xlabel('Lambda')\n",
    "plt.title('Difference Between groups at Lambda Values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def test(lambdas_):\n",
    "    X_train_unprotected_debiased = debias_features(Xs_train_np, Xs_train_p, lambdas_)\n",
    "    X_train_debiased = np.concatenate([X_train_unprotected_debiased, Xs_train_p], axis=1)\n",
    "    n_features = X_train.shape[1]\n",
    "    corr_ = np.zeros((n_features, n_features))\n",
    "    p_ = np.zeros((n_features, n_features))\n",
    "    for i in range(n_features):\n",
    "        for j in range(n_features):\n",
    "            corr_[i,j], p_[i,j] = pearsonr(X_train_debiased[:,i], X_train_debiased[:,j])\n",
    "            corr_ = np.nan_to_num(corr_, 0)\n",
    "    return corr_\n",
    "    \n",
    "corr1 = test(0)\n",
    "corr2 = test(0.5)\n",
    "corr3 = test(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3)\n",
    "\n",
    "y = ['Gender', 'Race']\n",
    "\n",
    "sns.heatmap(corr1[:,54:], cmap=\"bwr\", xticklabels=y, vmin=-1, vmax=1, ax=ax1, cbar=False)\n",
    "\n",
    "sns.heatmap(corr2[:,54:], cmap=\"bwr\", xticklabels=y, vmin=-1, vmax=1, ax=ax2, cbar=False)\n",
    "\n",
    "sns.heatmap(corr3[:,54:], cmap=\"bwr\", xticklabels=y, vmin=-1, vmax=1, ax=ax3)\n",
    "\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "\n",
    "\n",
    "# plt.suptitle('\\n'.join([\"Pearson's Correlation Coeff between SEX and other variables (Masked by p value)\"]), y=1.02)\n",
    "ax1.set_title(\"lambda = \" + str(0), fontsize=10)\n",
    "ax2.set_title(\"lambda = \" + str(0.5), fontsize=10)\n",
    "ax3.set_title(\"lambda = \" + str(1), fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.2 - FairPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reprojecting data using FairPCA\n",
    "\n",
    "We use the FairPCA method from the exercise 7 solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class FairPCA:\n",
    "    def __init__(self, Xs, p_idxs, n_components):\n",
    "        self.fit(Xs, p_idxs, n_components)\n",
    "\n",
    "    def fit(self, Xs, p_idxs, n_components):\n",
    "        # Extract protected features\n",
    "        Xs_p = Xs[:, p_idxs]\n",
    "\n",
    "        # Compute projection matrix (U)\n",
    "        Z = Xs_p\n",
    "        # Z = Z - Z.mean(0) # Since we alredy standardised everything, there is not much sense in removing the mean\n",
    "        R = scipy.linalg.null_space(Z.T @ Xs)\n",
    "        eig_vals, L = scipy.linalg.eig(R.T @ Xs.T @ Xs @ R)\n",
    "        self.U = R @ L[:, :n_components]\n",
    "\n",
    "    def project(self, Xs):\n",
    "        return Xs @ self.U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running FairPCA + Calculating Accuracies and Absolute Differences\n",
    "\n",
    "Below cell loops from 54 to 1 $(i)$, and for each loop:\n",
    " - Uses above FairPCA method to reproject the data down to $i$ dimensions\n",
    " - Fits a new model to the reprojected data\n",
    " - Seperates the data by the projected groups\n",
    " - Calculates accuracies for each of the groups\n",
    " - Calculates absolute difference of the accuracies between the groups\n",
    " - Stores the accuracies and absolute difference into the Pandas DataFrame \"fairPCA_graph_df\" for later graphing\n",
    "\n",
    "The cell can take up to 10 minutes depending on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('scaler', StandardScaler()), ('classifier', gbc)])\n",
    "\n",
    "# Do FairPCA from 53 and all the way down to 1 dimension, plotting for each dimension\n",
    "fairPCA_graph_df = pd.DataFrame()\n",
    "for i in reversed(range(1, 54)):\n",
    "    # do fairPCA\n",
    "    fair_pca = FairPCA(X_train.to_numpy(), [54, 55], i)\n",
    "    X_train_debiased = fair_pca.project(X_train)\n",
    "    X_test_debiased = fair_pca.project(X_test)\n",
    "\n",
    "    # fit model\n",
    "    pipe.fit(X_train_debiased, y_train)\n",
    "\n",
    "    # seperate by groups\n",
    "    test_women_idx = X_test[X_test['SEX_Female'] > 0].index\n",
    "    X_test_debiased_women = X_test_debiased.iloc[test_women_idx, :]\n",
    "    y_test_women = y_test.iloc[test_women_idx, :]\n",
    "\n",
    "    test_men_idx = X_test[X_test['SEX_Female'] < 0].index\n",
    "    X_test_debiased_men = X_test_debiased.iloc[test_men_idx, :]\n",
    "    y_test_men = y_test.iloc[test_men_idx, :]\n",
    "\n",
    "    test_black_idx = X_test[X_test['RAC1P_Black or African American alone'] > 0].index\n",
    "    X_test_debiased_black = X_test_debiased.iloc[test_black_idx, :]\n",
    "    y_test_black = y_test.iloc[test_black_idx, :]\n",
    "\n",
    "    test_non_black_idx = X_test[X_test['RAC1P_Black or African American alone'] < 0].index\n",
    "    X_test_debiased_non_black = X_test_debiased.iloc[test_non_black_idx, :]\n",
    "    y_test_non_black = y_test.iloc[test_non_black_idx, :]\n",
    "\n",
    "    # calculate accuracies\n",
    "    accuracy_all = accuracy_score(y_test, pipe.predict(X_test_debiased))\n",
    "    accuracy_women = accuracy_score(y_test_women, pipe.predict(X_test_debiased_women))\n",
    "    accuracy_men = accuracy_score(y_test_men, pipe.predict(X_test_debiased_men))\n",
    "    accuracy_black = accuracy_score(y_test_black, pipe.predict(X_test_debiased_black))\n",
    "    accuracy_non_black = accuracy_score(y_test_non_black, pipe.predict(X_test_debiased_non_black))\n",
    "\n",
    "    # storing stats\n",
    "    fairPCA_graph_df.loc[i, 'Accuracy All'] = accuracy_all\n",
    "    fairPCA_graph_df.loc[i, 'Accuracy Women'] = accuracy_women\n",
    "    fairPCA_graph_df.loc[i, 'Accuracy Men'] = accuracy_men\n",
    "    fairPCA_graph_df.loc[i, 'Accuracy Black'] = accuracy_black\n",
    "    fairPCA_graph_df.loc[i, 'Accuracy Non-Black'] = accuracy_non_black\n",
    "\n",
    "    # calcing and storing absolute differences\n",
    "    abs_diff = 0\n",
    "    groups = [accuracy_all, accuracy_women, accuracy_men, accuracy_black, accuracy_non_black]\n",
    "    for group_a in groups:\n",
    "        for group_b in groups:\n",
    "            abs_diff += abs(group_a - group_b)\n",
    "    fairPCA_graph_df.loc[i, 'Difference'] = abs_diff\n",
    "\n",
    "    # optional prints\n",
    "    # print(f'========== Dimension {i} ==========')\n",
    "    # print(f'Accuracy All:        {round(accuracy_all*100, 2)}')\n",
    "    # print(f'Accuracy Women:      {round(accuracy_women*100, 2)}')\n",
    "    # print(f'Accuracy Men:        {round(accuracy_men*100, 2)}')\n",
    "    # print(f'Accuracy Black:      {round(accuracy_black*100, 2)}')\n",
    "    # print(f'Accuracy Non-Black:  {round(accuracy_non_black*100, 2)}')\n",
    "    # print(f'Absolute difference: {abs_diff}\\n')\n",
    "\n",
    "fairPCA_graph_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.lineplot(data=fairPCA_graph_df, x=fairPCA_graph_df.index, y='Accuracy All', label='All', markers=True)\n",
    "sns.lineplot(data=fairPCA_graph_df, x=fairPCA_graph_df.index, y='Accuracy Men', label='Men', markers=True)\n",
    "sns.lineplot(data=fairPCA_graph_df, x=fairPCA_graph_df.index, y='Accuracy Women', label='Women', markers=True)\n",
    "sns.lineplot(data=fairPCA_graph_df, x=fairPCA_graph_df.index, y='Accuracy Black', label='Black', markers=True)\n",
    "sns.lineplot(data=fairPCA_graph_df, x=fairPCA_graph_df.index, y='Accuracy Non-Black', label='Non-Black', markers=True)\n",
    "plt.title('Accuracies of FairPCA trained models with different dimensions')\n",
    "plt.xlabel('Dimensions')\n",
    "plt.ylabel('Accuracy')\n",
    "# move legend to bottom right\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Absolute Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# plot the absolute differences\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.lineplot(data=fairPCA_graph_df, x=fairPCA_graph_df.index, y='Difference', markers=True)\n",
    "plt.title('Difference between groups at different dimensions')\n",
    "plt.xlabel('Dimensions')\n",
    "plt.ylabel('Absolute difference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Coeff Visualizations on FairPCA down to 21 and 30 dimensions\n",
    "\n",
    "This ended up not making the cut for the paper due to max page limit.\n",
    "\n",
    "It is however interesting to see that pearsons correlation shows no correlations (even if the data is reprojected to the same dimensions as original), but the spearmans correlation shows there are still some correlations in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def corr_vis(dim, return_=False):\n",
    "    fair_pca = FairPCA(X_train.to_numpy(), [54, 55], dim)\n",
    "    Xs_train_debiased = fair_pca.project(X_train)\n",
    "\n",
    "    # Compute correlation matrix\n",
    "    Xs_train_debiased_p = np.concatenate([Xs_train_debiased, Xs_train_p], axis=1)\n",
    "    n_features = Xs_train_debiased_p.shape[1]\n",
    "    pear_corr_ = np.zeros((n_features, n_features))\n",
    "    p_ = np.zeros((n_features, n_features))\n",
    "    spear_corr_ = np.zeros((n_features, n_features))\n",
    "    s_ = np.zeros((n_features, n_features))\n",
    "    for i in range(n_features):\n",
    "        for j in range(n_features):\n",
    "            pear_corr_[i,j], p_[i,j] = pearsonr(Xs_train_debiased_p[:,i], Xs_train_debiased_p[:,j])\n",
    "            pear_corr_ = np.nan_to_num(pear_corr_, 0)\n",
    "            spear_corr_[i,j], s_[i,j] = spearmanr(Xs_train_debiased_p[:,i], Xs_train_debiased_p[:,j])\n",
    "            spear_corr_ = np.nan_to_num(spear_corr_, 0)\n",
    "    \n",
    "    # return the spearman values for making later combined figure\n",
    "    if return_:\n",
    "        return spear_corr_[:,-2:], features.columns[-2:]\n",
    "\n",
    "    # Plot pearson correlations with protected features\n",
    "    plt.figure(figsize=(4,15))\n",
    "    sns.heatmap(pear_corr_[:,-2:], cmap=\"bwr\", xticklabels=features.columns[-2:], vmin=-1, vmax=1)\n",
    "    plt.title(\"Pearson's Correlation Coeff between protected variables and components (Masked by p value)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot spearman correlations with protected features\n",
    "    plt.figure(figsize=(4,15))\n",
    "    sns.heatmap(spear_corr_[:,-2:], cmap=\"bwr\", xticklabels=features.columns[-2:], vmin=-1, vmax=1)\n",
    "    plt.title(\"Spearman's Correlation Coeff between protected variables and components (Masked by p value)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "corr_vis(30)\n",
    "corr_vis(25)\n",
    "corr_vis(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3)\n",
    "\n",
    "x = ['Gender', 'Race']\n",
    "\n",
    "y, _ = corr_vis(30, return_=True)\n",
    "sns.heatmap(y, cmap=\"bwr\", xticklabels=x, vmin=-1, vmax=1, ax=ax1, cbar=False)\n",
    "\n",
    "y, _ = corr_vis(25, return_=True)\n",
    "sns.heatmap(y, cmap=\"bwr\", xticklabels=x, vmin=-1, vmax=1, ax=ax2, cbar=False)\n",
    "\n",
    "y, _ = corr_vis(21, return_=True)\n",
    "sns.heatmap(y, cmap=\"bwr\", xticklabels=x, vmin=-1, vmax=1, ax=ax3)\n",
    "\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "\n",
    "# plt.suptitle('\\n'.join(['Spearman Correlation between protected variables and', 'components for different FairPCA dimensions']), y=1.02)\n",
    "ax1.set_title('Dimension 30', fontsize=10)\n",
    "ax2.set_title('Dimension 25', fontsize=10)\n",
    "ax3.set_title('Dimension 21', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
