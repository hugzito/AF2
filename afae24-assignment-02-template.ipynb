{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Fairness, Accountability, and Ethics, Spring 2024\n",
    "\n",
    "## Mandatory Assignment 2\n",
    "\n",
    "Please use the following code to prepare the dataset.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables.acs import adult_filter\n",
    "from folktables import ACSDataSource, BasicProblem, generate_categories\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(0)\n",
    "from sklearn.utils.validation import check_random_state\n",
    "check_random_state(0)\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "\n",
    "\n",
    "def adult_filter(data):\n",
    "    \"\"\"Mimic the filters in place for Adult data.\n",
    "    Adult documentation notes: Extraction was done by Barry Becker from\n",
    "    the 1994 Census database. A set of reasonably clean records was extracted\n",
    "    using the following conditions:\n",
    "    ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
    "    \"\"\"\n",
    "    df = data\n",
    "    df = df[df['AGEP'] > 16]\n",
    "    df = df[df['PINCP'] > 100]\n",
    "    df = df[df['WKHP'] > 0]\n",
    "    df = df[df['PWGTP'] >= 1]\n",
    "    df = df[df[\"RAC1P\"] < 3] ## keep only Whites and African-Americans\n",
    "    return df\n",
    "\n",
    "\n",
    "ACSIncomeNew = BasicProblem(\n",
    "    features=[\n",
    "        'AGEP',\n",
    "        'COW',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'RELP',\n",
    "        'WKHP',\n",
    "        'PWGTP',\n",
    "        'SEX',\n",
    "        'RAC1P',\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > 25000,    \n",
    "    group=['SEX', 'RAC1P'],\n",
    "    preprocess=adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n",
    "\n",
    "definition_df = data_source.get_definitions(download=True)\n",
    "categories = generate_categories(features=ACSIncomeNew.features, definition_df=definition_df)\n",
    "features, labels, groups = ACSIncomeNew.df_to_pandas(acs_data, categories=categories, dummies=True)\n",
    "\n",
    "# Drop the \"redundant\" columns\n",
    "features = features.drop([\"RAC1P_White alone\", \n",
    "                          \"SEX_Male\", \n",
    "                          \"SCHL_1 or more years of college credit, no degree\",  \n",
    "                          \"MAR_Divorced\", \n",
    "                          \"RELP_Adopted son or daughter\",\n",
    "                          'COW_Working without pay in family business or farm' ], axis = 1) \n",
    "\n",
    "print(\"Columns with the protected features:\")\n",
    "for i, f in enumerate(features.columns):\n",
    "    if (\"RAC1P\" in f) or (\"SEX\" in f):\n",
    "        print(\"Column ID: %s\" %i, \"(%s)\"%f)\n",
    "        \n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sample_indices = random.sample(range(len(features)), 20000)\n",
    "features1, labels1 = features.iloc[sample_indices], labels.iloc[sample_indices]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features1, labels1, test_size=0.2, random_state=0)\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(columns= X_train.columns, data= X_train, index = X_train.index)\n",
    "X_test = pd.DataFrame(columns= X_test.columns, data = X_test, index= X_test.index)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "### Create one classifier to predict income on RAW DATA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "### Report general accuracy \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, auc, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "probs = gbc.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "preds = accuracy_score(y_test, probs > 0.5)\n",
    "\n",
    "print('Scores across all groups.')\n",
    "print('AUC: ', auc(fpr, tpr))\n",
    "print('Accuracy: ', preds)\n",
    "pipe = Pipeline(steps=[('scaler', StandardScaler()), ('classifier', gbc)])\n",
    "print('Overall cross val score: ', cross_val_score(pipe , X_train, y_train).mean())\n",
    "print('---------------------------')\n",
    "\n",
    "### report accuracy for gender groups and races\n",
    "accuracies_female, accuracies_nonfemale = [], []\n",
    "accuracies_black, accuracies_nonblack = [], []\n",
    "for j in [0, 4000, 8000, 12000]:\n",
    "    test = list(range(j, j+4000))\n",
    "    X_test_temp = X_train.iloc[test]\n",
    "    y_test_temp = y_train.iloc[test]\n",
    "    X_train_temp = X_train.drop(test)\n",
    "    y_train_temp = y_train.drop(test)\n",
    "    pipe = Pipeline(steps=[('scaler', StandardScaler()), ('classifier', gbc)])\n",
    "    pipe.fit(X_train_temp, y_train_temp)\n",
    "    for i in set(X_train['RAC1P_Black or African American alone']):\n",
    "        X_test_temp_group = X_test_temp[X_test_temp['RAC1P_Black or African American alone'] == i]\n",
    "        y_test_temp_group = y_test_temp.loc[X_test_temp_group.index]\n",
    "        temp_preds = pipe.predict(X_test_temp_group)\n",
    "        accuracy = accuracy_score(y_test_temp_group, temp_preds)\n",
    "        if i > 0:\n",
    "            accuracies_black.append(accuracy)\n",
    "        else:\n",
    "            accuracies_nonblack.append(accuracy)\n",
    "    for i in set(X_train['SEX_Female']):\n",
    "        X_test_temp_group = X_test_temp[X_test_temp['SEX_Female'] == i]\n",
    "        y_test_temp_group = y_test_temp.loc[X_test_temp_group.index]\n",
    "        temp_preds = pipe.predict(X_test_temp_group)\n",
    "        accuracy = accuracy_score(y_test_temp_group, temp_preds)\n",
    "        if i > 0:\n",
    "            accuracies_female.append(accuracy)\n",
    "        else:\n",
    "            accuracies_nonfemale.append(accuracy)\n",
    "\n",
    "print(f'Accuracy for Black: {np.mean(accuracies_black)}')\n",
    "print(f'Accuracy for Non-Black: {np.mean(accuracies_nonblack)}')\n",
    "print(f'Accuracy for Female: {np.mean(accuracies_female)}')\n",
    "print(f'Accuracy for Non-Female: {np.mean(accuracies_nonfemale)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_black, accuracies_nonblack = [], []\n",
    "\n",
    "for j in [0, 4000, 8000, 12000]:\n",
    "    test = list(range(j, j+4000))\n",
    "    X_test_temp = X_train.iloc[test]\n",
    "    y_test_temp = y_train.iloc[test]\n",
    "    X_train_temp = X_train.drop(test)\n",
    "    y_train_temp = y_train.drop(test)\n",
    "    pipe = Pipeline(steps=[('scaler', StandardScaler()), ('classifier', gbc)])\n",
    "    pipe.fit(X_train_temp, y_train_temp)\n",
    "    for i in set(X_train['RAC1P_Black or African American alone']):\n",
    "        X_test_temp_group = X_test_temp[X_test_temp['RAC1P_Black or African American alone'] == i]\n",
    "        y_test_temp_group = y_test_temp.loc[X_test_temp_group.index]\n",
    "        temp_preds = pipe.predict(X_test_temp_group)\n",
    "        accuracy = accuracy_score(y_test_temp_group, temp_preds)\n",
    "        if i > 0:\n",
    "            accuracies_black.append(accuracy)\n",
    "        else:\n",
    "            accuracies_nonblack.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features['RAC1P_Black or African American alone'].value_counts()/len(features))\n",
    "print(features1['RAC1P_Black or African American alone'].value_counts()/len(features1))\n",
    "print(features['SEX_Female'].value_counts()/len(features))\n",
    "print(features1['SEX_Female'].value_counts()/len(features1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(data = scaler.fit_transform(X_train), columns = X_train.columns, index = X_train.index)\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "Xs_train_p = X_train.values[:, 54:]\n",
    "Xs_test_p = X_test.values[:, 54:]\n",
    "Xs_train_np = X_train.values[:, :54]\n",
    "Xs_test_np = X_test.values[:, :54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Create a fairer version of the dataset to protect select groups\n",
    "# protected_cols = ['RAC1P_Black or African American alone','SEX_Female']\n",
    "# X_train_unprotected, X_train_protected = X_train.drop(columns = protected_cols), X_train[protected_cols]\n",
    "# X_test_unprotected, X_test_protected = X_test.drop(columns = protected_cols), X_test[protected_cols]\n",
    "\n",
    "plots = [0.96969697, 1.97979798, 3.03030303, 0.04040404]\n",
    "def debias_features(Xs_np, Xs_p, lambda_param=0.7):\n",
    "    import scipy\n",
    "    assert Xs_np.shape[0]==Xs_p.shape[0]\n",
    "    \n",
    "    # Find orthonormal basis of protected features\n",
    "    orthbasis = scipy.linalg.orth(Xs_p)\n",
    "\n",
    "    # Debias nonprotected features\n",
    "    if 'Xs_np_debiased1' not in globals():\n",
    "        global Xs_np_debiased1\n",
    "        Xs_np_debiased1 = (orthbasis @ orthbasis.T @ Xs_np)\n",
    "    Xs_np_debiased = Xs_np - lambda_param * Xs_np_debiased1\n",
    "    # Return debiased nonprotected features\n",
    "    return Xs_np_debiased\n",
    "\n",
    "accuracies_all = []\n",
    "accuracies_sex_1 = []\n",
    "accuracies_sex_2 = []\n",
    "accuracies_race_1 = []\n",
    "accuracies_race_2 = []\n",
    "protected_cols = ['RAC1P_Black or African American alone', 'SEX_Female']\n",
    "pipe = Pipeline(steps=[('classifier', gbc)])\n",
    "\n",
    "lambdas = np.linspace(0, 10, 100)\n",
    "# lambdas = [0, 0.1, 1/3, 0.5, 2/3, 1, 2, 3, 4]\n",
    "for idx, i in enumerate(lambdas):\n",
    "    X_train_unprotected_debiased = debias_features(Xs_train_np, Xs_train_p, i)\n",
    "    X_train_debiased = np.concatenate([X_train_unprotected_debiased, Xs_train_p], axis=1)\n",
    "    # Train a classifier on the debiased data for each group\n",
    "    pipe.fit(X_train_debiased, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    accuracies_all.append(accuracy)\n",
    "    X_test_women = X_test[X_test['SEX_Female'] > 0]\n",
    "    X_test_men = X_test[X_test['SEX_Female'] < 0]\n",
    "    y_test_men = y_test.loc[X_test_men.index]\n",
    "    y_test_women = y_test.loc[X_test_women.index]\n",
    "    X_test_black = X_test[X_test['RAC1P_Black or African American alone'] > 0]\n",
    "    X_test_non_black = X_test[X_test['RAC1P_Black or African American alone'] < 0]\n",
    "    y_test_black = y_test.loc[X_test_black.index]\n",
    "    y_test_non_black = y_test.loc[X_test_non_black.index]\n",
    "    accuracies_race_1.append(accuracy_score(y_test_black, pipe.predict(X_test_black)))\n",
    "    accuracies_race_2.append(accuracy_score(y_test_non_black, pipe.predict(X_test_non_black)))\n",
    "    accuracies_sex_1.append(accuracy_score(y_test_women, pipe.predict(X_test_women)))\n",
    "    accuracies_sex_2.append(accuracy_score(y_test_men, pipe.predict(X_test_men)))\n",
    "del Xs_np_debiased1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame()\n",
    "stats.index = lambdas\n",
    "stats['All'] = accuracies_all\n",
    "stats['Women'] = accuracies_sex_1\n",
    "stats['Men'] = accuracies_sex_2\n",
    "stats['Black'] = accuracies_race_1\n",
    "stats['Non-Black'] = accuracies_race_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[lambdas[0],lambdas[10], lambdas[25], lambdas[50], lambdas[75], lambdas[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate([lambdas[0],lambdas[10], lambdas[25], lambdas[50], lambdas[75], lambdas[-1]]):\n",
    "    X_train_unprotected_debiased = debias_features(Xs_train_np, Xs_train_p, i)\n",
    "    X_train_debiased = np.concatenate([X_train_unprotected_debiased, Xs_train_p], axis=1)\n",
    "    # Compute correlation matrix\n",
    "    n_features = X_train.shape[1]\n",
    "    corr_ = np.zeros((n_features, n_features))\n",
    "    p_ = np.zeros((n_features, n_features))\n",
    "    for i in range(n_features):\n",
    "        for j in range(n_features):\n",
    "            corr_[i,j], p_[i,j] = pearsonr(X_train_debiased[:,i], X_train_debiased[:,j])\n",
    "            corr_ = np.nan_to_num(corr_, 0)\n",
    "    plt.figure(idx, figsize=(4,15))\n",
    "    sns.heatmap(corr_[:,54:], cmap=\"bwr\", xticklabels=features.columns[54:], yticklabels=features.columns, vmin=-1, vmax=1)\n",
    "    plt.title(\"Pearson's Correlation Coeff between SEX and other variables (Masked by p value)\")\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build model using de-correlation effect from https://dl.acm.org/doi/10.1145/3375627.3375864\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.lineplot(data=stats, x = stats.index, y = stats['All'], label = 'All', markers=True)\n",
    "sns.lineplot(data=stats, x = stats.index, y = 'Men', label = 'men', markers=True)\n",
    "sns.lineplot(data=stats, x = stats.index, y = 'Women', label = 'Women', markers=True)\n",
    "sns.lineplot(data=stats, x = stats.index, y = 'Black', label = 'Black', markers=True)\n",
    "sns.lineplot(data=stats, x = stats.index, y = 'Non-Black', label = 'Non-Black', markers=True)\n",
    "plt.title(\"Accuracy of the model across different groups\")\n",
    "plt.xlabel(\"Lambda\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "# move legend to upper left \n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_at_val(val):\n",
    "    print('Testing for value: ', val)\n",
    "    desired_val = val\n",
    "    arr_val = min(lambdas, key = lambda x: abs(x-desired_val))\n",
    "    if type(arr_val) == tuple:\n",
    "        arr_val = arr_val[0]\n",
    "    lambda_idx = np.where(lambdas == arr_val)[0][0]\n",
    "    ethnic_diff = abs(accuracies_race_1[lambda_idx] - accuracies_race_2[lambda_idx])\n",
    "    sex_diff = abs(accuracies_sex_1[lambda_idx] - accuracies_sex_2[lambda_idx])\n",
    "\n",
    "    print(f'Ethnic diff: {ethnic_diff}')\n",
    "    print(f'Gender diff: {sex_diff}')\n",
    "\n",
    "    total_diff = 0\n",
    "    accuracies = [accuracies_race_1[lambda_idx], accuracies_race_2[lambda_idx], accuracies_sex_1[lambda_idx], accuracies_sex_2[lambda_idx]]\n",
    "    print('Average Accuracy : ',np.mean(accuracies))\n",
    "    for group_a in accuracies:\n",
    "        for group_b in accuracies:\n",
    "            total_diff += abs(group_a - group_b)\n",
    "    print(f'Total diff: {total_diff}\\n')\n",
    "corr_at_val(0)\n",
    "corr_at_val(0.5)\n",
    "corr_at_val(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy for Black', accuracies_race_1)\n",
    "print('Accuracy for Non-Black', accuracies_race_2)\n",
    "print('Accuracy for Women', accuracies_sex_1)\n",
    "print('Accuracy for Men', accuracies_sex_2)\n",
    "print('Accuracy for all', accuracies_all)\n",
    "\n",
    "diff_sex = []\n",
    "diff_race = []\n",
    "for i in zip(accuracies_race_1, accuracies_race_2, accuracies_sex_1, accuracies_sex_2):\n",
    "    diff_race.append(abs( i[0] - i[1]))\n",
    "    diff_sex.append(abs(i[2] - i[3]))\n",
    "overall_diff = []\n",
    "for i in zip(diff_race, diff_sex):\n",
    "    overall_diff.append(i[0] + i[1])\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.lineplot(x=stats.index, y = diff_race, label = 'Race')\n",
    "sns.lineplot(x = stats.index, y = diff_sex, label = 'Sex')\n",
    "sns.lineplot(x = stats.index, y = overall_diff, label = 'Overall')\n",
    "plt.ylabel('% Difference')\n",
    "plt.xlabel('Lambda Value')\n",
    "plt.title('Difference Between groups at Lambda Values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.2 - FairPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reprojecting data using FairPCA implementation from exercise 7 solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairPCA:\n",
    "    def __init__(self, Xs, p_idxs, n_components):\n",
    "        self.fit(Xs, p_idxs, n_components)\n",
    "\n",
    "    def fit(self, Xs, p_idxs, n_components):\n",
    "        # Extract protected features\n",
    "        Xs_p = Xs[:, p_idxs]\n",
    "\n",
    "        # Compute projection matrix (U)\n",
    "        Z = Xs_p\n",
    "        # Z = Z - Z.mean(0) # Since we alredy standardised everything, there is not much sense in removing the mean\n",
    "        R = scipy.linalg.null_space(Z.T @ Xs)\n",
    "        eig_vals, L = scipy.linalg.eig(R.T @ Xs.T @ Xs @ R)\n",
    "        self.U = R @ L[:, :n_components]\n",
    "\n",
    "    def project(self, Xs):\n",
    "        return Xs @ self.U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('scaler', StandardScaler()), ('classifier', gbc)])\n",
    "\n",
    "# Do FairPCA from 53 and all the way down to 1 dimension, plotting for each dimension\n",
    "fairPCA_graph_df = pd.DataFrame()\n",
    "for i in reversed(range(1, 54)):\n",
    "    # do fairPCA\n",
    "    fair_pca = FairPCA(X_train.to_numpy(), [54, 55], i)\n",
    "    X_train_debiased = fair_pca.project(X_train)\n",
    "    X_test_debiased = fair_pca.project(X_test)\n",
    "\n",
    "    # fit model\n",
    "    pipe.fit(X_train_debiased, y_train)\n",
    "\n",
    "    # seperate by groups\n",
    "    test_women_idx = X_test[X_test['SEX_Female'] > 0].index\n",
    "    X_test_debiased_women = X_test_debiased.iloc[test_women_idx, :]\n",
    "    y_test_women = y_test.iloc[test_women_idx, :]\n",
    "\n",
    "    test_men_idx = X_test[X_test['SEX_Female'] < 0].index\n",
    "    X_test_debiased_men = X_test_debiased.iloc[test_men_idx, :]\n",
    "    y_test_men = y_test.iloc[test_men_idx, :]\n",
    "\n",
    "    test_black_idx = X_test[X_test['RAC1P_Black or African American alone'] > 0].index\n",
    "    X_test_debiased_black = X_test_debiased.iloc[test_black_idx, :]\n",
    "    y_test_black = y_test.iloc[test_black_idx, :]\n",
    "\n",
    "    test_non_black_idx = X_test[X_test['RAC1P_Black or African American alone'] < 0].index\n",
    "    X_test_debiased_non_black = X_test_debiased.iloc[test_non_black_idx, :]\n",
    "    y_test_non_black = y_test.iloc[test_non_black_idx, :]\n",
    "\n",
    "    # calculate accuracies\n",
    "    accuracy_all = accuracy_score(y_test, pipe.predict(X_test_debiased))\n",
    "    accuracy_women = accuracy_score(y_test_women, pipe.predict(X_test_debiased_women))\n",
    "    accuracy_men = accuracy_score(y_test_men, pipe.predict(X_test_debiased_men))\n",
    "    accuracy_black = accuracy_score(y_test_black, pipe.predict(X_test_debiased_black))\n",
    "    accuracy_non_black = accuracy_score(y_test_non_black, pipe.predict(X_test_debiased_non_black))\n",
    "\n",
    "    # storing stats\n",
    "    fairPCA_graph_df.loc[i, 'Accuracy All'] = accuracy_all\n",
    "    fairPCA_graph_df.loc[i, 'Accuracy Women'] = accuracy_women\n",
    "    fairPCA_graph_df.loc[i, 'Accuracy Men'] = accuracy_men\n",
    "    fairPCA_graph_df.loc[i, 'Accuracy Black'] = accuracy_black\n",
    "    fairPCA_graph_df.loc[i, 'Accuracy Non-Black'] = accuracy_non_black\n",
    "\n",
    "    # calcing and storing absolute differences\n",
    "    abs_diff = 0\n",
    "    groups = [accuracy_all, accuracy_women, accuracy_men, accuracy_black, accuracy_non_black]\n",
    "    for group_a in groups:\n",
    "        for group_b in groups:\n",
    "            abs_diff += abs(group_a - group_b)\n",
    "    fairPCA_graph_df.loc[i, 'Difference'] = abs_diff\n",
    "\n",
    "    # optional prints\n",
    "    # print(f'========== Accuracies for {i} dimensions ==========')\n",
    "    # print(f'Accuracy All:        {round(accuracy_all*100, 2)}')\n",
    "    # print(f'Accuracy Women:      {round(accuracy_women*100, 2)}')\n",
    "    # print(f'Accuracy Men:        {round(accuracy_men*100, 2)}')\n",
    "    # print(f'Accuracy Black:      {round(accuracy_black*100, 2)}')\n",
    "    # print(f'Accuracy Non-Black:  {round(accuracy_non_black*100, 2)}')\n",
    "    # print(f'Absolute difference: {abs_diff}\\n')\n",
    "\n",
    "fairPCA_graph_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracies\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.lineplot(data=fairPCA_graph_df, x=fairPCA_graph_df.index, y='Accuracy All', label='All', markers=True)\n",
    "sns.lineplot(data=fairPCA_graph_df, x=fairPCA_graph_df.index, y='Accuracy Men', label='Men', markers=True)\n",
    "sns.lineplot(data=fairPCA_graph_df, x=fairPCA_graph_df.index, y='Accuracy Women', label='Women', markers=True)\n",
    "sns.lineplot(data=fairPCA_graph_df, x=fairPCA_graph_df.index, y='Accuracy Black', label='Black', markers=True)\n",
    "sns.lineplot(data=fairPCA_graph_df, x=fairPCA_graph_df.index, y='Accuracy Non-Black', label='Non-Black', markers=True)\n",
    "plt.title('Accuracies of FairPCA trained models with different dimensions')\n",
    "plt.xlabel('Dimensions')\n",
    "plt.ylabel('Accuracy')\n",
    "# move legend to bottom right\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the absolute differences\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.lineplot(data=fairPCA_graph_df, x=fairPCA_graph_df.index, y='Difference', markers=True)\n",
    "plt.title('Difference between groups at different dimensions')\n",
    "plt.xlabel('Dimensions')\n",
    "plt.ylabel('Absolute difference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Coeff Visualizations on FairPCA down to 21 and 30 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_vis(dim):\n",
    "    fair_pca = FairPCA(X_train.to_numpy(), [54, 55], dim)\n",
    "    Xs_train_debiased = fair_pca.project(X_train)\n",
    "\n",
    "    # Compute correlation matrix\n",
    "    Xs_train_debiased_p = np.concatenate([Xs_train_debiased, Xs_train_p], axis=1)\n",
    "    n_features = Xs_train_debiased_p.shape[1]\n",
    "    pear_corr_ = np.zeros((n_features, n_features))\n",
    "    p_ = np.zeros((n_features, n_features))\n",
    "    spear_corr_ = np.zeros((n_features, n_features))\n",
    "    s_ = np.zeros((n_features, n_features))\n",
    "    for i in range(n_features):\n",
    "        for j in range(n_features):\n",
    "            pear_corr_[i,j], p_[i,j] = pearsonr(Xs_train_debiased_p[:,i], Xs_train_debiased_p[:,j])\n",
    "            pear_corr_ = np.nan_to_num(pear_corr_, 0)\n",
    "            spear_corr_[i,j], s_[i,j] = spearmanr(Xs_train_debiased_p[:,i], Xs_train_debiased_p[:,j])\n",
    "            spear_corr_ = np.nan_to_num(spear_corr_, 0)\n",
    "\n",
    "    # Plot pearson correlations with protected features\n",
    "    plt.figure(figsize=(4,15))\n",
    "    sns.heatmap(pear_corr_[:,-2:], cmap=\"bwr\", xticklabels=features.columns[-2:], vmin=-1, vmax=1)\n",
    "    plt.title(\"Pearson's Correlation Coeff between protected variables and components (Masked by p value)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot spearman correlations with protected features\n",
    "    plt.figure(figsize=(4,15))\n",
    "    sns.heatmap(spear_corr_[:,-2:], cmap=\"bwr\", xticklabels=features.columns[-2:], vmin=-1, vmax=1)\n",
    "    plt.title(\"Spearman's Correlation Coeff between protected variables and components (Masked by p value)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_vis(30)\n",
    "corr_vis(21)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
